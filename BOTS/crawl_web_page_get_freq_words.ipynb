{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import fnmatch, glob, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 program for a word frequency \n",
    "# counter after crawling a web-page \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import operator \n",
    "from collections import Counter \n",
    "  \n",
    "'''Function defining the web-crawler/core \n",
    "spider, which will fetch information from \n",
    "a given website, and push the contents to \n",
    "the second  function clean_wordlist()'''\n",
    "def start(url): \n",
    "  \n",
    "    # empty list to store the contents of  \n",
    "    # the website fetched from our web-crawler \n",
    "    wordlist = [] \n",
    "    source_code = requests.get(url).text \n",
    "  \n",
    "    # BeautifulSoup object which will \n",
    "    # ping the requested url for data \n",
    "    soup = BeautifulSoup(source_code, 'html.parser') \n",
    "  \n",
    "    # Text in given web-page is stored under \n",
    "    # the <div> tags with class <entry-content> \n",
    "    for each_text in soup.findAll('div', {'class':'entry-content'}): \n",
    "        content = each_text.text \n",
    "  \n",
    "        # use split() to break the sentence into  \n",
    "        # words and convert them into lowercase  \n",
    "        words = content.lower().split() \n",
    "          \n",
    "        for each_word in words: \n",
    "            wordlist.append(each_word) \n",
    "        clean_wordlist(wordlist) \n",
    "  \n",
    "# Function removes any unwanted symbols \n",
    "def clean_wordlist(wordlist): \n",
    "      \n",
    "    clean_list =[] \n",
    "    for word in wordlist: \n",
    "        symbols = '!@#$%^&*()_-+={[}]|\\;:\"<>?/., '\n",
    "          \n",
    "        for i in range (0, len(symbols)): \n",
    "            word = word.replace(symbols[i], '') \n",
    "              \n",
    "        if len(word) > 0: \n",
    "            clean_list.append(word) \n",
    "    create_dictionary(clean_list) \n",
    "  \n",
    "# Creates a dictionary conatining each word's  \n",
    "# count and top_20 ocuuring words \n",
    "def create_dictionary(clean_list): \n",
    "    word_count = {} \n",
    "      \n",
    "    for word in clean_list: \n",
    "        if word in word_count: \n",
    "            word_count[word] += 1\n",
    "        else: \n",
    "            word_count[word] = 1\n",
    "              \n",
    "    ''' To get count of each word in \n",
    "        the crawled page --> \n",
    "          \n",
    "    # operator.itemgetter() takes one  \n",
    "    # parameter either 1(denotes keys) \n",
    "    # or 0 (denotes corresponding values) \n",
    "      \n",
    "    for key, value in sorted(word_count.items(), \n",
    "                    key = operator.itemgetter(1)): \n",
    "        print (\"% s : % s \" % (key, value)) \n",
    "          \n",
    "    <-- '''\n",
    "  \n",
    "      \n",
    "    c = Counter(word_count) \n",
    "      \n",
    "    # returns the most occuring elements \n",
    "    top = c.most_common(10) \n",
    "    print(top) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code \n",
    "if __name__ == '__main__': \n",
    "    start(\"https://www.reddit.com/r/all/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
